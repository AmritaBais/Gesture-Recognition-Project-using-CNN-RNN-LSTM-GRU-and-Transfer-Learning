{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## PG Diploma in Machine Learning and AI from IIIT Bangalore | Upgrad\n",
        "## Developed by:\n",
        "### 1. Amrita Bais - Group facilitator\n",
        "### 2. Archana Kumari"
      ],
      "metadata": {
        "id": "nP9OWc-NeBvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Learning Course Project - Gesture Recognition"
      ],
      "metadata": {
        "id": "oSu6l_bIeBNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem Statement\n",
        "Imagine you are working as a data scientist at a home electronics company which manufactures state of the art smart televisions. You want to develop a cool feature in the smart-TV that can recognise five different gestures performed by the user which will help users control the TV without using a remote.\n",
        "\n",
        "The gestures are continuously monitored by the webcam mounted on the TV. Each gesture corresponds to a specific command:\n",
        "1. Thumbs up:  Increase the volume\n",
        "2. Thumbs down: Decrease the volume\n",
        "3. Left swipe: 'Jump' backwards 10 seconds\n",
        "4. Right swipe: 'Jump' forward 10 seconds  \n",
        "5. Stop: Pause the movie\n",
        " \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ujxe44u4eljh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZy7OeqVdm2t"
      },
      "source": [
        "# Gesture Recognition\n",
        "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAfjbCNNVuxE",
        "outputId": "64fcd7a5-b9ec-422e-dfbc-6fb392df8010"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G_gfOGGXQeb",
        "outputId": "5394a9dc-9f83-402e-ed60-b896893ed26b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "-_B6ey-Qdm22"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import imageio\n",
        "from imageio import imread\n",
        "from PIL import Image\n",
        "import datetime\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import abc\n",
        "from sys import getsizeof\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mW1IJYJdm24"
      },
      "source": [
        "We set the random seed so that the results don't vary drastically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "HzAZyB_Cdm25"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "metadata": {
        "id": "bjT7yLatf8pG"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zwn9ExRdm26"
      },
      "source": [
        "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout\n"
      ],
      "metadata": {
        "id": "YJKfiKNagEU1"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_folder='/content/drive/MyDrive/Project_data'"
      ],
      "metadata": {
        "id": "vgxGlqo9gKSh"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(history):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
        "    axes[0].plot(history.history['loss'])   \n",
        "    axes[0].plot(history.history['val_loss'])\n",
        "    axes[0].legend(['loss','val_loss'])\n",
        "\n",
        "    axes[1].plot(history.history['categorical_accuracy'])   \n",
        "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
        "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "4ReZVgoRgMb-"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNXO4bnqgMqR",
        "outputId": "375364af-4449-4994-de00-e6da04af508e"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "RCSrYeO3dm27"
      },
      "outputs": [],
      "source": [
        "train_doc = np.random.permutation(open('/content/drive/MyDrive/Project_data/train.csv').readlines())\n",
        "val_doc = np.random.permutation(open('/content/drive/MyDrive/Project_data/val.csv').readlines())\n",
        "batch_size = 51"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WOGEYgydm28"
      },
      "source": [
        "## Generator\n",
        "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelBuilder(metaclass= abc.ABCMeta):\n",
        "    # initialisng the path where project data resides\n",
        "    def initialize_path(self,project_folder):\n",
        "        self.train_doc = np.random.permutation(open(project_folder + '/' + 'train.csv').readlines())\n",
        "        self.val_doc = np.random.permutation(open(project_folder + '/' + 'val.csv').readlines())\n",
        "        self.train_path = project_folder + '/' + 'train'\n",
        "        self.val_path =  project_folder + '/' + 'val'\n",
        "        self.num_train_sequences = len(self.train_doc)\n",
        "        self.num_val_sequences = len(self.val_doc)\n",
        "    # initialising the image properties    \n",
        "    def initialize_image_properties(self,image_height=100,image_width=100):\n",
        "        self.image_height=image_height\n",
        "        self.image_width=image_width\n",
        "        self.channels=3\n",
        "        self.num_classes=5\n",
        "        self.total_frames=30\n",
        "    # initialising the batch size, frames to sample and the no. of epochs\n",
        "    def initialize_hyperparams(self,frames_to_sample=30,batch_size=20,num_epochs=20):\n",
        "        self.frames_to_sample=frames_to_sample\n",
        "        self.batch_size=batch_size\n",
        "        self.num_epochs=num_epochs\n",
        "        \n",
        "    # MOST IMPORTANT PART HERE - The generator function        \n",
        "    def generator(self,source_path, folder_list, augment=False):\n",
        "        img_idx = np.round(np.linspace(0,self.total_frames-1,self.frames_to_sample)).astype(int)\n",
        "        batch_size=self.batch_size\n",
        "        while True:\n",
        "            t = np.random.permutation(folder_list)\n",
        "            num_batches = len(t)//batch_size\n",
        "        \n",
        "            for batch in range(num_batches): \n",
        "                batch_data, batch_labels= self.one_batch_data(source_path,t,batch,batch_size,img_idx,augment)\n",
        "                yield batch_data, batch_labels \n",
        "\n",
        "            remaining_seq=len(t)%batch_size\n",
        "        \n",
        "            if (remaining_seq != 0):\n",
        "                batch_data, batch_labels= self.one_batch_data(source_path,t,num_batches,batch_size,img_idx,augment,remaining_seq)\n",
        "                yield batch_data, batch_labels \n",
        "\n",
        "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
        "    \n",
        "        seq_len = remaining_seq if remaining_seq else batch_size\n",
        "    \n",
        "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
        "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
        "    \n",
        "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
        "\n",
        "        \n",
        "        for folder in range(seq_len): \n",
        "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
        "            for idx,item in enumerate(img_idx):\n",
        "                #performing image reading and resizing\n",
        "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                image_resized=image.resize(image,(self.image_height,self.image_width,3))\n",
        "            \n",
        "                #normalizing the images\n",
        "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
        "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
        "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
        "            \n",
        "                if (augment):\n",
        "                    shifted = cv2.warpAffine(image, \n",
        "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
        "                                            (image.shape[1], image.shape[0]))\n",
        "                    \n",
        "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
        "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
        "                    # cropping the images to have the targeted gestures and remove the noise from the images.\n",
        "                    cropped=shifted[x0:x1,y0:y1,:]\n",
        "                    \n",
        "                    image_resized=imageio.crop(cropped,(self.image_height,self.image_width,3))\n",
        "                    \n",
        "                    #shifted = cv2.warpAffine(image_resized, \n",
        "                    #                        np.float32([[1, 0, np.random.randint(-3,3)],[0, 1, np.random.randint(-3,3)]]), \n",
        "                    #                        (image_resized.shape[1], image_resized.shape[0]))\n",
        "            \n",
        "                    batch_data_aug[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
        "                    batch_data_aug[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
        "                    batch_data_aug[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
        "                \n",
        "            \n",
        "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "\n",
        "            if(augment):\n",
        "               batch_data=np.concatenate([batch_data,batch_data_aug])\n",
        "               batch_labels=np.concatenate([batch_labels,batch_labels])\n",
        "\n",
        "        \n",
        "        return(batch_data,batch_labels)\n",
        "    \n",
        "    \n",
        "    def train_model(self, model, augment_data=False):\n",
        "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
        "        val_generator = self.generator(self.val_path, self.val_doc)\n",
        "\n",
        "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "        if not os.path.exists(model_name):\n",
        "            os.mkdir(model_name)\n",
        "        \n",
        "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq=1)\n",
        "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
        "        \n",
        "        earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
        "        callbacks_list = [checkpoint, LR, earlystop]\n",
        "\n",
        "        if (self.num_train_sequences%self.batch_size) == 0:\n",
        "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
        "        else:\n",
        "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
        "\n",
        "        if (self.num_val_sequences%self.batch_size) == 0:\n",
        "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
        "        else:\n",
        "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
        "    \n",
        "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
        "                            callbacks=callbacks_list, validation_data=val_generator, \n",
        "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
        "        return history\n",
        "\n",
        "        \n",
        "    @abc.abstractmethod\n",
        "    def define_model(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M1U7sC74In87"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exn5960Ddm2_"
      },
      "source": [
        "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t3zv3f3dm3B",
        "outputId": "8cd0115b-a80a-4038-9a64-12a8ca533688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# training sequences = 663\n",
            "# validation sequences = 100\n",
            "# epochs = 15\n"
          ]
        }
      ],
      "source": [
        "curr_dt_time = datetime.datetime.now()\n",
        "train_path = '/content/drive/MyDrive/Project_data/train'\n",
        "val_path = '/content/drive/MyDrive/Project_data/val'\n",
        "num_train_sequences = len(train_doc)\n",
        "print('# training sequences =', num_train_sequences)\n",
        "num_val_sequences = len(val_doc)\n",
        "print('# validation sequences =', num_val_sequences)\n",
        "num_epochs = 15 # choose the number of epochs\n",
        "print ('# epochs =', num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH5Qnb_Adm3C"
      },
      "source": [
        "## Model\n",
        "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils"
      ],
      "metadata": {
        "id": "qujAo8XLMcyT"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D1(ModelBuilder):\n",
        "    \n",
        "    def define_model(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Dense(64,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "        optimiser = tf.keras.optimizers.Adam(lr=0.001)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        print (model.summary())\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "WzOQOrLpJQf4"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experimenting with Image resolution, number of frames to use and batch_sizeÂ¶"
      ],
      "metadata": {
        "id": "vaTFA4PusCLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Memory util is {} Gigs\". format(getsizeof(np.zeros((40,16,30,160,160)))/(1024*1024*1024)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9F6P3sQsRuQ",
        "outputId": "e43f0f43-2ebd-4918-fb69-4104f13c1576"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory util is 3.662109524011612 Gigs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=30,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "metadata": {
        "id": "yVUG2WI8NPIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=60,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "metadata": {
        "id": "ZFz4oLZqNVSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGzvQKwxdm3E"
      },
      "source": [
        "Below are the experiments to see how training time is affected by image resolution, number of images in sequence and batch size."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=60,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "metadata": {
        "id": "jjXvFzfiBurc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=80,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "metadata": {
        "id": "i-Ahrv1IBxG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=15,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "metadata": {
        "id": "iTe0W09DB0Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=15,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "metadata": {
        "id": "xkhPbdRiB26K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=15,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "metadata": {
        "id": "LtVkenuPB5Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=10,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "metadata": {
        "id": "ai2Zm8_yB8WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=10,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "metadata": {
        "id": "NGhAb_agCAs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=10,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "metadata": {
        "id": "yVQVrKYoCEzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=10,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "metadata": {
        "id": "uQovUUQaCH_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=16,batch_size=40,num_epochs=2)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "conv_3d1.train_model(conv_3d1_model)"
      ],
      "metadata": {
        "id": "BxEIKKbPCLG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So experimentations are carried with batch size fixed around 15-40 and changing the resolution and number of image per sequence based on the device memory constraints . Models are designed such that their memory foot print is less than 50 MB which corresponds to 4.3 million parameters assuming the datatype size of parameters to be 12 bytes"
      ],
      "metadata": {
        "id": "3jqrDJtLCX8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 1 - Base Model - No Data Augmentation Batch Size 40 and Epoch 15**"
      ],
      "metadata": {
        "id": "WDRcSzltCYXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D1(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam()\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "TnFkQvKhCaVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d1=ModelConv3D1()\n",
        "conv_3d1.initialize_path(project_folder)\n",
        "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d1.initialize_hyperparams(frames_to_sample=20,batch_size=40,num_epochs=15)\n",
        "conv_3d1_model=conv_3d1.define_model()\n",
        "conv_3d1_model.summary()"
      ],
      "metadata": {
        "id": "Fp-0r7IGCsi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d1_model.count_params())\n",
        "history_model1 = conv_3d1.train_model(conv_3d1_model)"
      ],
      "metadata": {
        "id": "IxJ9_27PCv5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model1)"
      ],
      "metadata": {
        "id": "gfn0kdJDC0TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 2 - Augment Data , (3,3,3) filter & 160x160 image resolution**"
      ],
      "metadata": {
        "id": "RErkIGbrC6Kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d2=ModelConv3D1()\n",
        "conv_3d2.initialize_path(project_folder)\n",
        "conv_3d2.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d2.initialize_hyperparams(frames_to_sample=20,batch_size=20,num_epochs=25)\n",
        "conv_3d2_model=conv_3d2.define_model(dense_neurons=256,dropout=0.5)\n",
        "conv_3d2_model.summary()"
      ],
      "metadata": {
        "id": "2Ui85ToiC3Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d2_model.count_params())\n",
        "history_model2=conv_3d2.train_model(conv_3d2_model,augment_data=True)"
      ],
      "metadata": {
        "id": "doi2y7kNDnAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model2)"
      ],
      "metadata": {
        "id": "IvUya4PXDnH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 3 - Reduce filter size to (2,2,2) and image res to 120 x 120**"
      ],
      "metadata": {
        "id": "MnEotiRoDyfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D3(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "rm7LgayUDuTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d3=ModelConv3D3()\n",
        "conv_3d3.initialize_path(project_folder)\n",
        "conv_3d3.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d3.initialize_hyperparams(frames_to_sample=16,batch_size=30,num_epochs=30)\n",
        "conv_3d3_model=conv_3d3.define_model(filtersize=(2,2,2),dense_neurons=256,dropout=0.5)\n",
        "conv_3d3_model.summary()"
      ],
      "metadata": {
        "id": "yfZVTqRVDuYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d3_model.count_params())\n",
        "history_model3=conv_3d3.train_model(conv_3d3_model,augment_data=True)"
      ],
      "metadata": {
        "id": "MiNmk-9ADnLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model3)"
      ],
      "metadata": {
        "id": "f7Jtl7q1EALZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 4 - Adding more layers**"
      ],
      "metadata": {
        "id": "vDd63o9MEHq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D4(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        \n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam()\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "N1-__eM9EASV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d4=ModelConv3D4()\n",
        "conv_3d4.initialize_path(project_folder)\n",
        "conv_3d4.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d4.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=30)\n",
        "conv_3d4_model=conv_3d4.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.5)\n",
        "conv_3d4_model.summary()"
      ],
      "metadata": {
        "id": "U3BT6rpqEAXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d4_model.count_params())\n",
        "history_model4=conv_3d4.train_model(conv_3d4_model,augment_data=True)"
      ],
      "metadata": {
        "id": "CbBI43mGEQZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model4)"
      ],
      "metadata": {
        "id": "vCZb1NM6EQjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 5 Adding dropout at convolution layers**"
      ],
      "metadata": {
        "id": "JYuvaTMJEe8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D5(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam()\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "Ph-0UKC8EZG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d5=ModelConv3D5()\n",
        "conv_3d5.initialize_path(project_folder)\n",
        "conv_3d5.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d5.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=22)\n",
        "conv_3d5_model=conv_3d5.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.25)\n",
        "conv_3d5_model.summary()"
      ],
      "metadata": {
        "id": "QYhCpKh_EZUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d5_model.count_params())\n",
        "history_model5=conv_3d5.train_model(conv_3d5_model,augment_data=True)"
      ],
      "metadata": {
        "id": "lEBN0MIWIWGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model5)"
      ],
      "metadata": {
        "id": "LhArP7nRIWS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All models experimental models above have more than 1 million parameters. Let's try to reduce the model size and see the performance"
      ],
      "metadata": {
        "id": "mm-Uq2hAIhLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 6 - reducing the number of parameters**"
      ],
      "metadata": {
        "id": "CFlBZ2ZTItk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D6(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "_6kekhbnEQvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d6=ModelConv3D6()\n",
        "conv_3d6.initialize_path(project_folder)\n",
        "conv_3d6.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d6.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=30)\n",
        "conv_3d6_model=conv_3d6.define_model(dense_neurons=128,dropout=0.25)\n",
        "conv_3d6_model.summary()"
      ],
      "metadata": {
        "id": "1OBeGgeZI3Wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d6_model.count_params())\n",
        "history_model6=conv_3d6.train_model(conv_3d6_model,augment_data=True)"
      ],
      "metadata": {
        "id": "ZVj3vDEAI3kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model6)"
      ],
      "metadata": {
        "id": "NKEiDZ6kI-I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 7 - reducing the number of parameters**"
      ],
      "metadata": {
        "id": "5Z20neiDJGEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D7(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, (3, 3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "3OogrMF-I-VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d7=ModelConv3D7()\n",
        "conv_3d7.initialize_path(project_folder)\n",
        "conv_3d7.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d7.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
        "conv_3d7_model=conv_3d7.define_model(dense_neurons=64,dropout=0.25)\n",
        "conv_3d7_model.summary()"
      ],
      "metadata": {
        "id": "ExK0om8oI3wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d7_model.count_params())\n",
        "history_model7=conv_3d7.train_model(conv_3d7_model,augment_data=True)"
      ],
      "metadata": {
        "id": "wH5BJ5IQJPpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model7)"
      ],
      "metadata": {
        "id": "z8OjR76WJMcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 8 - reducing the number of parameters**"
      ],
      "metadata": {
        "id": "RwpUgHEqMFZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D8(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(8, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "NBGWE1dMJMo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d8=ModelConv3D8()\n",
        "conv_3d8.initialize_path(project_folder)\n",
        "conv_3d8.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d8.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=30)\n",
        "conv_3d8_model=conv_3d8.define_model(dense_neurons=64,dropout=0.25)\n",
        "conv_3d8_model.summary()"
      ],
      "metadata": {
        "id": "A69qQuw8MMrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d8_model.count_params())\n",
        "history_model8=conv_3d8.train_model(conv_3d8_model,augment_data=True)"
      ],
      "metadata": {
        "id": "0Wb_xz-HMH4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model8)"
      ],
      "metadata": {
        "id": "4gtWldF5MUGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 9 - CNN- LSTM Model**"
      ],
      "metadata": {
        "id": "DMzy0iLHgcS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNCNN1(ModelBuilder):\n",
        "    \n",
        "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
        "                                  input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(256, (3, 3) , padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        #model.add(TimeDistributed(Conv2D(512, (2, 2) , padding='valid', activation='relu')))\n",
        "       # model.add(TimeDistributed(BatchNormalization()))\n",
        "       # model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "\n",
        "        model.add(TimeDistributed(Flatten()))\n",
        "        \n",
        "        model.add(LSTM(lstm_cells))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(self.num_classes, activation='softmax'))\n",
        "        optimiser = optimizers.Adam()\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model\n"
      ],
      "metadata": {
        "id": "CoVJZ-uNMU6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_cnn1=RNNCNN1()\n",
        "rnn_cnn1.initialize_path(project_folder)\n",
        "rnn_cnn1.initialize_image_properties(image_height=120,image_width=120)\n",
        "rnn_cnn1.initialize_hyperparams(frames_to_sample=18,batch_size=20,num_epochs=20)\n",
        "rnn_cnn1_model=rnn_cnn1.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
        "rnn_cnn1_model.summary()"
      ],
      "metadata": {
        "id": "jcpBY_iLgosD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", rnn_cnn1_model.count_params())\n",
        "history_model9=rnn_cnn1.train_model(rnn_cnn1_model,augment_data=True)"
      ],
      "metadata": {
        "id": "LXj8eVu5gvDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model9)"
      ],
      "metadata": {
        "id": "8qYcXISDgvN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**More Augmentation**"
      ],
      "metadata": {
        "id": "zxJCvyyCheVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelBuilderMoreAugmentation(metaclass= abc.ABCMeta):\n",
        "    \n",
        "    def initialize_path(self,project_folder):\n",
        "        self.train_doc = np.random.permutation(open(project_folder + '/' + 'train.csv').readlines())\n",
        "        self.val_doc = np.random.permutation(open(project_folder + '/' + 'val.csv').readlines())\n",
        "        self.train_path = project_folder + '/' + 'train'\n",
        "        self.val_path =  project_folder + '/' + 'val'\n",
        "        self.num_train_sequences = len(self.train_doc)\n",
        "        self.num_val_sequences = len(self.val_doc)\n",
        "        \n",
        "    def initialize_image_properties(self,image_height=100,image_width=100):\n",
        "        self.image_height=image_height\n",
        "        self.image_width=image_width\n",
        "        self.channels=3\n",
        "        self.num_classes=5\n",
        "        self.total_frames=30\n",
        "          \n",
        "    def initialize_hyperparams(self,frames_to_sample=30,batch_size=20,num_epochs=20):\n",
        "        self.frames_to_sample=frames_to_sample\n",
        "        self.batch_size=batch_size\n",
        "        self.num_epochs=num_epochs\n",
        "\n",
        "    def generator(self,source_path, folder_list, augment=False):\n",
        "        img_idx = np.round(np.linspace(0,self.total_frames-1,self.frames_to_sample)).astype(int)\n",
        "        batch_size=self.batch_size\n",
        "        while True:\n",
        "            t = np.random.permutation(folder_list)\n",
        "            num_batches = len(t)//batch_size\n",
        "        \n",
        "            for batch in range(num_batches): \n",
        "                batch_data, batch_labels= self.one_batch_data(source_path,t,batch,batch_size,img_idx,augment)\n",
        "                yield batch_data, batch_labels \n",
        "\n",
        "            remaining_seq=len(t)%batch_size\n",
        "        \n",
        "            if (remaining_seq != 0):\n",
        "                batch_data, batch_labels= self.one_batch_data(source_path,t,num_batches,batch_size,img_idx,augment,remaining_seq)\n",
        "                yield batch_data, batch_labels \n",
        "    \n",
        "    \n",
        "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
        "    \n",
        "        seq_len = remaining_seq if remaining_seq else batch_size\n",
        "    \n",
        "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
        "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
        "    \n",
        "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
        "\n",
        "        \n",
        "        for folder in range(seq_len): \n",
        "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
        "            for idx,item in enumerate(img_idx): \n",
        "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                image_resized=imresize(image,(self.image_height,self.image_width,3))\n",
        "            \n",
        "\n",
        "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
        "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
        "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
        "            \n",
        "                if (augment):\n",
        "                    shifted = cv2.warpAffine(image, \n",
        "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
        "                                            (image.shape[1], image.shape[0]))\n",
        "                    \n",
        "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
        "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
        "                    \n",
        "                    cropped=shifted[x0:x1,y0:y1,:]\n",
        "                    \n",
        "                    image_resized=imresize(cropped,(self.image_height,self.image_width,3))\n",
        "                    \n",
        "                    M = cv2.getRotationMatrix2D((self.image_width//2,self.image_height//2),\n",
        "                                                np.random.randint(-10,10), 1.0)\n",
        "                    rotated = cv2.warpAffine(image_resized, M, (self.image_width, self.image_height))\n",
        "                    \n",
        "                    #shifted = cv2.warpAffine(image_resized, \n",
        "                    #                        np.float32([[1, 0, np.random.randint(-3,3)],[0, 1, np.random.randint(-3,3)]]), \n",
        "                    #                        (image_resized.shape[1], image_resized.shape[0]))\n",
        "            \n",
        "                    batch_data_aug[folder,idx,:,:,0] = (rotated[:,:,0])/255\n",
        "                    batch_data_aug[folder,idx,:,:,1] = (rotated[:,:,1])/255\n",
        "                    batch_data_aug[folder,idx,:,:,2] = (rotated[:,:,2])/255\n",
        "                \n",
        "            \n",
        "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            \n",
        "    \n",
        "        if (augment):\n",
        "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
        "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
        "\n",
        "        \n",
        "        return(batch_data,batch_labels)\n",
        "    \n",
        "    \n",
        "    def train_model(self, model, augment_data=False):\n",
        "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
        "        val_generator = self.generator(self.val_path, self.val_doc)\n",
        "\n",
        "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "        if not os.path.exists(model_name):\n",
        "            os.mkdir(model_name)\n",
        "        \n",
        "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
        "        callbacks_list = [checkpoint, LR]\n",
        "\n",
        "        if (self.num_train_sequences%self.batch_size) == 0:\n",
        "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
        "        else:\n",
        "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
        "\n",
        "        if (self.num_val_sequences%self.batch_size) == 0:\n",
        "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
        "        else:\n",
        "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
        "    \n",
        "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
        "                            callbacks=callbacks_list, validation_data=val_generator, \n",
        "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
        "        return history\n",
        "\n",
        "        \n",
        "    @abc.abstractmethod\n",
        "    def define_model(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "CJ4zexUagvWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 10 - (3,3,3) Filter & 160x160 Image resolution - similar to Model 2**"
      ],
      "metadata": {
        "id": "D9GGfLa2iHIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D10(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "PjILvE6NiKCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d10=ModelConv3D10()\n",
        "conv_3d10.initialize_path(project_folder)\n",
        "conv_3d10.initialize_image_properties(image_height=160,image_width=160)\n",
        "conv_3d10.initialize_hyperparams(frames_to_sample=20,batch_size=20,num_epochs=30)\n",
        "conv_3d10_model=conv_3d10.define_model(dense_neurons=256,dropout=0.5)\n",
        "conv_3d10_model.summary()"
      ],
      "metadata": {
        "id": "jijo5_C0iKSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d10_model.count_params())\n",
        "history_model10=conv_3d10.train_model(conv_3d10_model,augment_data=True)"
      ],
      "metadata": {
        "id": "RkamtPe5iKcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model10)"
      ],
      "metadata": {
        "id": "6CpFd3lFiKf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 11 - (2,2,2) Filter & 120x120 Image resolution - similar to Model 3**"
      ],
      "metadata": {
        "id": "TGvl0qCc_Qfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D11(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "tlQnzlxRiKiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d11=ModelConv3D11()\n",
        "conv_3d11.initialize_path(project_folder)\n",
        "conv_3d11.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d11.initialize_hyperparams(frames_to_sample=16,batch_size=30,num_epochs=30)\n",
        "conv_3d11_model=conv_3d11.define_model(filtersize=(2,2,2),dense_neurons=256,dropout=0.5)\n",
        "conv_3d11_model.summary()"
      ],
      "metadata": {
        "id": "srYPBJUqiKk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d11_model.count_params())\n",
        "history_model11=conv_3d11.train_model(conv_3d11_model,augment_data=True)"
      ],
      "metadata": {
        "id": "NLIXgwVa_aI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model11)"
      ],
      "metadata": {
        "id": "K7uUDqf7iKnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 12 - Adding more layers - Similar to model 4**"
      ],
      "metadata": {
        "id": "-8G7sU8t_kTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D12(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        \n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "gyLc0gUoiKsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d12=ModelConv3D12()\n",
        "conv_3d12.initialize_path(project_folder)\n",
        "conv_3d12.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d12.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=30)\n",
        "conv_3d12_model=conv_3d12.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.5)\n",
        "conv_3d12_model.summary()"
      ],
      "metadata": {
        "id": "ESMvrws5hFbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d12_model.count_params())\n",
        "history_model12=conv_3d12.train_model(conv_3d12_model,augment_data=True)"
      ],
      "metadata": {
        "id": "hCJ4z-dZhFk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model12)"
      ],
      "metadata": {
        "id": "Ko1qEREYhFsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 13 - Adding dropouts - Similar to Model 5**"
      ],
      "metadata": {
        "id": "gy45XphG_1L3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D13(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(16, filtersize, padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(32, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(64, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(Conv3D(128, filtersize, padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        \n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "YE7Pf82agveq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d13=ModelConv3D13()\n",
        "conv_3d13.initialize_path(project_folder)\n",
        "conv_3d13.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d13.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
        "conv_3d13_model=conv_3d13.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.25)\n",
        "conv_3d13_model.summary()"
      ],
      "metadata": {
        "id": "bhASv8YAgvmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d13_model.count_params())\n",
        "history_model13=conv_3d13.train_model(conv_3d13_model,augment_data=True)"
      ],
      "metadata": {
        "id": "jzq8kOzw_8Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model13)"
      ],
      "metadata": {
        "id": "ny1qbT5Y_8bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 14 - reducing network parameters - Similar to Model 6**"
      ],
      "metadata": {
        "id": "DRQlX9u8AK_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D14(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "Az87CH0OMUQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d14=ModelConv3D14()\n",
        "conv_3d14.initialize_path(project_folder)\n",
        "conv_3d14.initialize_image_properties(image_height=100,image_width=100)\n",
        "conv_3d14.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=30)\n",
        "conv_3d14_model=conv_3d14.define_model(dense_neurons=128,dropout=0.25)\n",
        "conv_3d14_model.summary()"
      ],
      "metadata": {
        "id": "OAL8FnrYAP_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yPYAD_gdAhH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d14_model.count_params())\n",
        "history_model14=conv_3d14.train_model(conv_3d14_model,augment_data=True)"
      ],
      "metadata": {
        "id": "QICAsUsmAUic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model14)"
      ],
      "metadata": {
        "id": "EeNuF6FUAUui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 15 - reducing network parameters - Similar to model 7**"
      ],
      "metadata": {
        "id": "TaC1cZNGAeCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D15(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, (3, 3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "9qugDD9mMUat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d15=ModelConv3D15()\n",
        "conv_3d15.initialize_path(project_folder)\n",
        "conv_3d15.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d15.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
        "conv_3d15_model=conv_3d15.define_model(dense_neurons=64,dropout=0.25)\n",
        "conv_3d15_model.summary()"
      ],
      "metadata": {
        "id": "YEbGOIckAo6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d15_model.count_params())\n",
        "history_model15=conv_3d15.train_model(conv_3d15_model,augment_data=True)"
      ],
      "metadata": {
        "id": "_Z9L0oLqApGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model15)"
      ],
      "metadata": {
        "id": "Sa-UTytPMIEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 16 - reducing network parameters - Similar to Model 8**"
      ],
      "metadata": {
        "id": "e-eipoExA0dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConv3D16(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv3D(8, (3, 3, 3), padding='same',\n",
        "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(16, (3, 3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "\n",
        "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        model.add(Dense(self.num_classes,activation='softmax'))\n",
        "\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "xZRNXk1iDnQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_3d16=ModelConv3D16()\n",
        "conv_3d16.initialize_path(project_folder)\n",
        "conv_3d16.initialize_image_properties(image_height=120,image_width=120)\n",
        "conv_3d16.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=30)\n",
        "conv_3d16_model=conv_3d16.define_model(dense_neurons=64,dropout=0.25)\n",
        "conv_3d16_model.summary()"
      ],
      "metadata": {
        "id": "jtBsz40iA-8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", conv_3d16_model.count_params())\n",
        "history_model16=conv_3d16.train_model(conv_3d16_model,augment_data=True)"
      ],
      "metadata": {
        "id": "7mbPJqRiA_Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model16)"
      ],
      "metadata": {
        "id": "QNbo52TOA2kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 17 - CNN LSTM with GRU - Similar to Model 9**"
      ],
      "metadata": {
        "id": "11xKcR7HCF3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNCNN2(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
        "                                  input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        \n",
        "\n",
        "        model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "\n",
        "        model.add(GRU(lstm_cells))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(self.num_classes, activation='softmax'))\n",
        "        optimiser = optimizers.Adam(lr=0.0002)\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "cw57ms1QA2xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_cnn2=RNNCNN2()\n",
        "rnn_cnn2.initialize_path(project_folder)\n",
        "rnn_cnn2.initialize_image_properties(image_height=120,image_width=120)\n",
        "rnn_cnn2.initialize_hyperparams(frames_to_sample=18,batch_size=20,num_epochs=20)\n",
        "rnn_cnn2_model=rnn_cnn2.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
        "rnn_cnn2_model.summary()"
      ],
      "metadata": {
        "id": "KebjMIiGCJA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", rnn_cnn2_model.count_params())\n",
        "history_model17=rnn_cnn2.train_model(rnn_cnn2_model,augment_data=True)"
      ],
      "metadata": {
        "id": "vgQVYsR4CJK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model17)"
      ],
      "metadata": {
        "id": "XnkF7blJCJVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 18 - Transfer Learning**"
      ],
      "metadata": {
        "id": "SeS9WjYhCelb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import mobilenet"
      ],
      "metadata": {
        "id": "1tGKWmJKB8ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
        "\n",
        "class RNNCNN_TL(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(TimeDistributed(mobilenet_transfer,input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        "        \n",
        "        \n",
        "        for layer in model.layers:\n",
        "            layer.trainable = False\n",
        "        \n",
        "        \n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "        model.add(LSTM(lstm_cells))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(self.num_classes, activation='softmax'))\n",
        "        \n",
        "        \n",
        "        optimiser = optimizers.Adam()\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "VI16CJzfCaFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_cnn_tl=RNNCNN_TL()\n",
        "rnn_cnn_tl.initialize_path(project_folder)\n",
        "rnn_cnn_tl.initialize_image_properties(image_height=120,image_width=120)\n",
        "rnn_cnn_tl.initialize_hyperparams(frames_to_sample=16,batch_size=5,num_epochs=20)\n",
        "rnn_cnn_tl_model=rnn_cnn_tl.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
        "rnn_cnn_tl_model.summary()"
      ],
      "metadata": {
        "id": "WgfI2vLnCjZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", rnn_cnn_tl_model.count_params())\n",
        "history_model18=rnn_cnn_tl.train_model(rnn_cnn_tl_model,augment_data=True)"
      ],
      "metadata": {
        "id": "KQhJjwcQCjlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model18)"
      ],
      "metadata": {
        "id": "qp4TpB7vCaPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 19 - Transfer Learning with GRU and training all weights**"
      ],
      "metadata": {
        "id": "h27YGmKiC2KQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import mobilenet\n",
        "\n",
        "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
        "\n",
        "class RNNCNN_TL2(ModelBuilderMoreAugmentation):\n",
        "    \n",
        "    def define_model(self,gru_cells=64,dense_neurons=64,dropout=0.25):\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(TimeDistributed(mobilenet_transfer,input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
        " \n",
        "        \n",
        "        model.add(TimeDistributed(BatchNormalization()))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
        "        model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "        model.add(GRU(gru_cells))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(dense_neurons,activation='relu'))\n",
        "        model.add(Dropout(dropout))\n",
        "        \n",
        "        model.add(Dense(self.num_classes, activation='softmax'))\n",
        "        \n",
        "        \n",
        "        optimiser = optimizers.Adam()\n",
        "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        return model"
      ],
      "metadata": {
        "id": "lIvyTitmC1O2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_cnn_tl2=RNNCNN_TL2()\n",
        "rnn_cnn_tl2.initialize_path(project_folder)\n",
        "rnn_cnn_tl2.initialize_image_properties(image_height=120,image_width=120)\n",
        "rnn_cnn_tl2.initialize_hyperparams(frames_to_sample=16,batch_size=5,num_epochs=20)\n",
        "rnn_cnn_tl2_model=rnn_cnn_tl2.define_model(gru_cells=128,dense_neurons=128,dropout=0.25)\n",
        "rnn_cnn_tl2_model.summary()"
      ],
      "metadata": {
        "id": "Em6kTneiDBJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Params:\", rnn_cnn_tl2_model.count_params())\n",
        "history_model19=rnn_cnn_tl2.train_model(rnn_cnn_tl2_model,augment_data=True)"
      ],
      "metadata": {
        "id": "fVrhrf3hC1aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history_model19)"
      ],
      "metadata": {
        "id": "2UlKX-i1DGaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading model and Testing**"
      ],
      "metadata": {
        "id": "aW1cEwMbDaCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from keras.models import load_model\n",
        "model = load_model('conv3d_model-10-0.39118-0.86425-0.59927-0.86000.h5')"
      ],
      "metadata": {
        "id": "J_JVmeJIDGpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator=ModelConv3D10()\n",
        "test_generator.initialize_path(project_folder)\n",
        "test_generator.initialize_image_properties(image_height=160,image_width=160)\n",
        "test_generator.initialize_hyperparams(frames_to_sample=20,batch_size=5,num_epochs=1)\n",
        "\n",
        "g=test_generator.generator(test_generator.val_path,test_generator.val_doc,augment=False)\n",
        "batch_data, batch_labels=next(g)"
      ],
      "metadata": {
        "id": "urAxyrS0Ddvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_labels"
      ],
      "metadata": {
        "id": "nhXC4WR9CaYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7xckaS8dm3H"
      },
      "outputs": [],
      "source": [
        "print(np.argmax(model.predict(batch_data[:,:,:,:,:]),axis=1))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Neural_Nets_Project_Starter_Code.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}